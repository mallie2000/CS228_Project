{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please run on Colab with T4 gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "damCjn-yB5g6",
    "outputId": "46855ab1-9277-478f-9e13-3ed7a90b621f"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install TTS\n",
    "!pip install torch\n",
    "!pip install audiocraft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJNBTfEiv0qj"
   },
   "source": [
    "## Music generation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PNrWdHEBv0CR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "from TTS.api import TTS\n",
    "from IPython.display import Audio\n",
    "from audiocraft.models import MusicGen\n",
    "from audiocraft.data.audio import audio_write\n",
    "import wave\n",
    "\n",
    "class GenerateAudio():\n",
    "    \"\"\"\n",
    "    A class to generate audio files based on a provided text input. The class generates\n",
    "    speech, classifies the sentiment of the text, and creates background music to accompany\n",
    "    the speech based on the classified sentiment.\n",
    "\n",
    "    Attributes:\n",
    "    device (str): The device to run the models on ('cuda' if GPU is available, 'cpu' otherwise).\n",
    "    text (str): The input text to generate speech and classify sentiment.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text):\n",
    "        \"\"\"\n",
    "        Initializes the GenerateAudio class with the provided text and sets up the device.\n",
    "\n",
    "        Parameters:\n",
    "        text (str): The input text for generating speech and sentiment analysis.\n",
    "        \"\"\"\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.text = text\n",
    "\n",
    "    def _generate_sentiment(self, candidate_labels=[\"happy\", \"sad\", \"scary\"]):\n",
    "        \"\"\"\n",
    "        Classifies the sentiment of the input text using a zero-shot classification model.\n",
    "\n",
    "        Parameters:\n",
    "        candidate_labels (list): A list of sentiment labels to classify the text. Default is\n",
    "                                  [\"happy\", \"sad\", \"scary\"].\n",
    "\n",
    "        Returns:\n",
    "        str: The label with the highest classification score indicating the sentiment of the text.\n",
    "        \"\"\"\n",
    "        classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=self.device)  # Run on GPU if available\n",
    "        result = classifier(self.text, candidate_labels)\n",
    "\n",
    "        labels_and_scores = list(zip(result['labels'], result['scores']))\n",
    "        best_label, best_score = max(labels_and_scores, key=lambda x: x[1])\n",
    "\n",
    "        return best_label\n",
    "\n",
    "    def _generate_speech(self, outfile='tts_output.wav'):\n",
    "        \"\"\"\n",
    "        Generates speech from the input text using a Tacotron 2 TTS model and saves it to a file.\n",
    "\n",
    "        Parameters:\n",
    "        outfile (str): The path to save the generated speech audio file. Default is 'tts_output.wav'.\n",
    "\n",
    "        Returns:\n",
    "        str: The path to the generated speech audio file.\n",
    "        \"\"\"\n",
    "        tts_model = TTS(model_name=\"tts_models/en/ljspeech/tacotron2-DDC\").to(self.device)\n",
    "        tts_model.tts_to_file(text=self.text, file_path=outfile)\n",
    "        return outfile\n",
    "\n",
    "    def _generate_background_music(self, label, duration, outfile=\"bg_audio\"):\n",
    "        \"\"\"\n",
    "        Generates background music based on a given label and duration using the MusicGen model.\n",
    "\n",
    "        Parameters:\n",
    "        label (str): The sentiment label used to guide the generation of background music.\n",
    "        duration (float): The duration (in seconds) for which the background music should play.\n",
    "        outfile (str): The path to save the generated background music file. Default is 'bg_audio'.\n",
    "\n",
    "        Returns:\n",
    "        str: The path to the generated background music audio file.\n",
    "        \"\"\"\n",
    "        model = MusicGen.get_pretrained('small', device=self.device)\n",
    "        model.set_generation_params(duration=duration)  # Duration of the generated waveform in seconds\n",
    "        output = model.generate(\n",
    "            descriptions=[f'{label} + Orchestral Background Music']\n",
    "        )\n",
    "\n",
    "        if outfile.endswith('.wav'):\n",
    "            outfile = outfile[:-4]\n",
    "\n",
    "        audio_write(stem_name=outfile, wav=output[0], sample_rate=model.sample_rate)\n",
    "        return outfile\n",
    "\n",
    "    def _find_duration(self, filePath):\n",
    "        \"\"\"\n",
    "        Calculates the duration of an audio file based on its sample rate and number of frames.\n",
    "\n",
    "        Parameters:\n",
    "        filePath (str): The path to the audio file.\n",
    "\n",
    "        Returns:\n",
    "        float: The duration of the audio file in seconds.\n",
    "        \"\"\"\n",
    "        with wave.open(filePath, 'rb') as audio_file:\n",
    "            sample_rate = audio_file.getframerate()  # Sample rate (Hz)\n",
    "            num_frames = audio_file.getnframes()    # Total number of frames\n",
    "            duration = num_frames / float(sample_rate)  # Duration in seconds\n",
    "        return duration\n",
    "\n",
    "    def create_audio_files(self, ttsPath, bgMusicPath):\n",
    "        \"\"\"\n",
    "        Creates speech and background music audio files based on the sentiment of the input text.\n",
    "\n",
    "        The function generates speech from the input text, calculates its duration,\n",
    "        and generates background music based on the classified sentiment.\n",
    "\n",
    "        Parameters:\n",
    "        ttsPath (str): The path to save the generated speech audio file.\n",
    "        bgMusicPath (str): The path to save the generated background music audio file.\n",
    "\n",
    "        Returns:\n",
    "        tuple: A tuple containing the paths to the generated speech and background music files.\n",
    "        \"\"\"\n",
    "        sentiment = self._generate_sentiment()\n",
    "        ttsPath = self._generate_speech(ttsPath)\n",
    "        duration = self._find_duration(ttsPath)\n",
    "        bgMusicPath = self._generate_background_music(sentiment, duration,outfile=bgMusicPath)\n",
    "\n",
    "        return ttsPath, bgMusicPath\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yE872i3s0S43",
    "outputId": "9f0ccf70-dc24-48c5-e22e-fe3fecc8855f"
   },
   "outputs": [],
   "source": [
    "obj = GenerateAudio(\"The dark forest gave me chills.\")\n",
    "obj.create_audio_files(\"tts_test.wav\",\"bg_audio_test.wav\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
