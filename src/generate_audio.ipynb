{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please run on Colab with T4 gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "damCjn-yB5g6",
    "outputId": "46855ab1-9277-478f-9e13-3ed7a90b621f"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install TTS\n",
    "!pip install torch\n",
    "!pip install audiocraft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJNBTfEiv0qj"
   },
   "source": [
    "## Music generation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PNrWdHEBv0CR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "from TTS.api import TTS\n",
    "from IPython.display import Audio\n",
    "from audiocraft.models import MusicGen\n",
    "from audiocraft.data.audio import audio_write\n",
    "import wave\n",
    "\n",
    "class GenerateAudio():\n",
    "    \"\"\"\n",
    "    A class to generate audio files based on a provided text input. The class generates\n",
    "    speech, classifies the sentiment of the text, and creates background music to accompany\n",
    "    the speech based on the classified sentiment.\n",
    "\n",
    "    Attributes:\n",
    "    device (str): The device to run the models on ('cuda' if GPU is available, 'cpu' otherwise).\n",
    "    text (str): The input text to generate speech and classify sentiment.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text):\n",
    "        \"\"\"\n",
    "        Initializes the GenerateAudio class with the provided text and sets up the device.\n",
    "\n",
    "        Parameters:\n",
    "        text (str): The input text for generating speech and sentiment analysis.\n",
    "        \"\"\"\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.text = text\n",
    "\n",
    "    def _generate_sentiment(self, candidate_labels=[\"happy\", \"sad\", \"scary\"]):\n",
    "        \"\"\"\n",
    "        Classifies the sentiment of the input text using a zero-shot classification model.\n",
    "\n",
    "        Parameters:\n",
    "        candidate_labels (list): A list of sentiment labels to classify the text. Default is\n",
    "                                  [\"happy\", \"sad\", \"scary\"].\n",
    "\n",
    "        Returns:\n",
    "        str: The label with the highest classification score indicating the sentiment of the text.\n",
    "        \"\"\"\n",
    "        classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=self.device)  # Run on GPU if available\n",
    "        result = classifier(self.text, candidate_labels)\n",
    "\n",
    "        labels_and_scores = list(zip(result['labels'], result['scores']))\n",
    "        best_label, best_score = max(labels_and_scores, key=lambda x: x[1])\n",
    "\n",
    "        return best_label\n",
    "\n",
    "    def _generate_speech(self, outfile='tts_output.wav'):\n",
    "        \"\"\"\n",
    "        Generates speech from the input text using a Tacotron 2 TTS model and saves it to a file.\n",
    "\n",
    "        Parameters:\n",
    "        outfile (str): The path to save the generated speech audio file. Default is 'tts_output.wav'.\n",
    "\n",
    "        Returns:\n",
    "        str: The path to the generated speech audio file.\n",
    "        \"\"\"\n",
    "        tts_model = TTS(model_name=\"tts_models/en/ljspeech/tacotron2-DDC\").to(self.device)\n",
    "        tts_model.tts_to_file(text=self.text, file_path=outfile)\n",
    "        return outfile\n",
    "\n",
    "    def _generate_background_music(self, label, duration, outfile=\"bg_audio\"):\n",
    "        \"\"\"\n",
    "        Generates background music based on a given label and duration using the MusicGen model.\n",
    "\n",
    "        Parameters:\n",
    "        label (str): The sentiment label used to guide the generation of background music.\n",
    "        duration (float): The duration (in seconds) for which the background music should play.\n",
    "        outfile (str): The path to save the generated background music file. Default is 'bg_audio'.\n",
    "\n",
    "        Returns:\n",
    "        str: The path to the generated background music audio file.\n",
    "        \"\"\"\n",
    "        model = MusicGen.get_pretrained('small', device=self.device)\n",
    "        model.set_generation_params(duration=duration)  # Duration of the generated waveform in seconds\n",
    "        output = model.generate(\n",
    "            descriptions=[f'{label} + Orchestral Background Music']\n",
    "        )\n",
    "\n",
    "        if outfile.endswith('.wav'):\n",
    "            outfile = outfile[:-4]\n",
    "\n",
    "        audio_write(stem_name=outfile, wav=output[0], sample_rate=model.sample_rate)\n",
    "        return outfile\n",
    "\n",
    "    def _find_duration(self, filePath):\n",
    "        \"\"\"\n",
    "        Calculates the duration of an audio file based on its sample rate and number of frames.\n",
    "\n",
    "        Parameters:\n",
    "        filePath (str): The path to the audio file.\n",
    "\n",
    "        Returns:\n",
    "        float: The duration of the audio file in seconds.\n",
    "        \"\"\"\n",
    "        with wave.open(filePath, 'rb') as audio_file:\n",
    "            sample_rate = audio_file.getframerate()  # Sample rate (Hz)\n",
    "            num_frames = audio_file.getnframes()    # Total number of frames\n",
    "            duration = num_frames / float(sample_rate)  # Duration in seconds\n",
    "        return duration\n",
    "\n",
    "    def create_audio_files(self, ttsPath, bgMusicPath):\n",
    "        \"\"\"\n",
    "        Creates speech and background music audio files based on the sentiment of the input text.\n",
    "\n",
    "        The function generates speech from the input text, calculates its duration,\n",
    "        and generates background music based on the classified sentiment.\n",
    "\n",
    "        Parameters:\n",
    "        ttsPath (str): The path to save the generated speech audio file.\n",
    "        bgMusicPath (str): The path to save the generated background music audio file.\n",
    "\n",
    "        Returns:\n",
    "        tuple: A tuple containing the paths to the generated speech and background music files.\n",
    "        \"\"\"\n",
    "        sentiment = self._generate_sentiment()\n",
    "        ttsPath = self._generate_speech(ttsPath)\n",
    "        duration = self._find_duration(ttsPath)\n",
    "        bgMusicPath = self._generate_background_music(sentiment, duration,outfile=bgMusicPath)\n",
    "\n",
    "        return ttsPath, bgMusicPath\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yE872i3s0S43",
    "outputId": "9f0ccf70-dc24-48c5-e22e-fe3fecc8855f"
   },
   "outputs": [],
   "source": [
    "obj = GenerateAudio(\"The dark forest gave me chills.\")\n",
    "obj.create_audio_files(\"tts_test.wav\",\"bg_audio_test.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace story text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from audiocraft.models import MusicGen\n",
    "from pydub import AudioSegment\n",
    "import soundfile as sf\n",
    "from TTS.api import TTS\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def generate_sentiment(text, candidate_labels=[\"happy\", \"sad\", \"scary\", \"adventurous\", \"calm\", \"cheerful\"]):\n",
    "    classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=0)  # Use GPU if available\n",
    "    result = classifier(text, candidate_labels)\n",
    "    return result['labels'][0]\n",
    "\n",
    "def generate_audio(text, outfile=\"tts_output.wav\"):\n",
    "    tts_model = TTS(model_name=\"tts_models/en/ljspeech/tacotron2-DDC\")\n",
    "    tts_model.tts_to_file(text=text, file_path=outfile)\n",
    "    return outfile\n",
    "\n",
    "def generate_background_music(label, duration, file_name=\"background_music.wav\"):\n",
    "    model = MusicGen.get_pretrained('facebook/musicgen-small') \n",
    "    model.device = device\n",
    "    model.set_generation_params(use_sampling=True, top_k=250, duration=duration)\n",
    "    outputs = model.generate(descriptions=[f\"{label} + Background Music\"], progress=True)\n",
    "    audio = outputs[0].cpu().numpy().squeeze()\n",
    "    sf.write(file_name, audio.T, samplerate=32000)\n",
    "    return file_name\n",
    "\n",
    "def crossfade_music_segments(sentiment_labels, segment_durations, crossfade_duration=2000):\n",
    "    combined_music = None\n",
    "    for i, (label, duration) in enumerate(zip(sentiment_labels, segment_durations)):\n",
    "        music_file = generate_background_music(label, duration)\n",
    "        music_segment = AudioSegment.from_wav(music_file)\n",
    "        \n",
    "        if combined_music is None:\n",
    "            combined_music = music_segment\n",
    "        else:\n",
    "            combined_music = combined_music.append(music_segment, crossfade=crossfade_duration)\n",
    "    \n",
    "    combined_music.export(\"combined_music.wav\", format=\"wav\")\n",
    "    return \"combined_music.wav\"\n",
    "\n",
    "def overlay_tts_on_music(tts_file, music_file, output_file):\n",
    "    tts_audio = AudioSegment.from_wav(tts_file)\n",
    "    music_audio = AudioSegment.from_wav(music_file)\n",
    "\n",
    "    music_audio = music_audio - 10\n",
    "    tts_audio = tts_audio + 5\n",
    "\n",
    "    tts_duration = len(tts_audio)\n",
    "    music_duration = len(music_audio)\n",
    "\n",
    "    if music_duration < tts_duration:\n",
    "        loops = tts_duration // music_duration + 1\n",
    "        music_audio = (music_audio * loops)[:tts_duration]\n",
    "    elif music_duration > tts_duration:\n",
    "        music_audio = music_audio[:tts_duration]\n",
    "\n",
    "    combined_audio = music_audio.overlay(tts_audio, position=0)\n",
    "    combined_audio.export(output_file, format=\"wav\")\n",
    "    print(f\"Overlayed audio saved to {output_file}\")\n",
    "\n",
    "def generate_story_audio(story_text, segment_length=500):\n",
    "    # Split the story into segments\n",
    "    segments = [story_text[i:i+segment_length] for i in range(0, len(story_text), segment_length)]\n",
    "    \n",
    "    # Analyze sentiment for each segment\n",
    "    sentiment_labels = [generate_sentiment(segment) for segment in segments]\n",
    "\n",
    "    # Generate music for each segment and crossfade\n",
    "    segment_durations = [10] * len(segments)\n",
    "    combined_music_file = crossfade_music_segments(sentiment_labels, segment_durations)\n",
    "\n",
    "    # Generate TTS for the entire story\n",
    "    tts_file = generate_audio(story_text)\n",
    "\n",
    "    # Overlay TTS on the combined music\n",
    "    overlay_tts_on_music(tts_file, combined_music_file, \"final_story_audio.wav\")\n",
    "    print(\"Final audio saved to final_story_audio.wav\")\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.replace(\"“\", '\"').replace(\"”\", '\"').replace(\"‘\", \"'\").replace(\"’\", \"'\")\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    text = text.replace(\"—\", \" - \").replace(\"–\", \"-\")\n",
    "    text = re.sub(r\"\\s+([?.!,])\", r\"\\1\", text)\n",
    "    text = re.sub(r\"([?.!,])\\s*\", r\"\\1 \", text)\n",
    "    text = text.strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "story_text = \"\"\"\n",
    "HIGH above the city, on a tall column, stood the statue of the Happy Prince.  He was gilded all over with thin leaves of fine gold, for eyes he had two bright sapphires, and a large red ruby glowed on his sword-hilt.\n",
    "He was very much admired indeed.  “He is as beautiful as a weathercock,” remarked one of the Town Councillors who wished to gain a reputation for having artistic tastes; “only not quite so useful,” he added, fearing lest people should think him unpractical, which he really was not.\n",
    "“Why can’t you be like the Happy Prince?” asked a sensible mother of her little boy who was crying for the moon.  “The Happy Prince never dreams of crying for anything.”\n",
    "“I am glad there is some one in the world who is quite happy,” muttered a disappointed man as he gazed at the wonderful statue.\n",
    "“He looks just like an angel,” said the Charity Children as they came out of the cathedral in their bright scarlet cloaks and their clean white pinafores.\n",
    "“How do you know?” said the Mathematical Master, “you have never seen one.”\n",
    "“Ah! but we have, in our dreams,” answered the children; and the Mathematical Master frowned and looked very severe, for he did not approve of children dreaming.\n",
    "One night there flew over the city a little Swallow.  His friends had gone away to Egypt six weeks before, but he had stayed behind, for he was in love with the most beautiful Reed.  He had met her early in the spring as he was flying down the river after a big yellow moth, and had been so attracted by her slender waist that he had stopped to talk to her.\n",
    "“Shall I love you?” said the Swallow, who liked to come to the point at once, and the Reed made him a low bow.  So he flew round and round her, touching the water with his wings, and making silver ripples.  This was his courtship, and it lasted all through the summer.\n",
    "“It is a ridiculous attachment,” twittered the other Swallows; “she has no money, and far too many relations”; and indeed the river was quite full of Reeds.  Then, when the autumn came they all flew away.\n",
    "After they had gone he felt lonely, and began to tire of his lady-love.\n",
    "\"\"\"\n",
    "cleaned_text = clean_text(story_text)\n",
    "\n",
    "generate_story_audio(cleaned_text)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
